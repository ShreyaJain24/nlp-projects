Using wiki-news-1M-300 word vectors


Dataset : nltk corpus -> Reuters (news) -> 10k examples = (distinct 1,720,901)
                        -> brown       -> 500 samples = 1,161,192 ~ (1M examples distinct words)
                        -> gutenberg -> distinct words -> 2,621,613


Refer to this: https://www.jeremyjordan.me/variational-autoencoders/